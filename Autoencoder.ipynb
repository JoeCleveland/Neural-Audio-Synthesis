{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to the location of the NSynth dataset on your machine\n",
    "files = os.listdir('/media/data/nsynth-train/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = 2500 #Length of the audio samples\n",
    "BATCH = 50 #Batch size\n",
    "START = 100 #Start sample of the audio sample\n",
    "\n",
    "#Training data\n",
    "X = torch.zeros(BATCH, LEN)\n",
    "\n",
    "for i in range(BATCH):\n",
    "    #Change this to the location of the NSynth dataset on your machine\n",
    "    sound, sr = torchaudio.load('/media/data/nsynth-train/audio/' + files[i])\n",
    "    \n",
    "    #Normalize the audio so samples are between 0 and 1\n",
    "    sound = sound[:, START:LEN+START]\n",
    "    sound = sound -sound.min()\n",
    "    sound = sound / (sound.max() + 0.001)\n",
    "\n",
    "    X[i] = sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder uses three layers of GRUs\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, insize, statesize, embedsize):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.statesize = statesize\n",
    "        \n",
    "        self.gateLayer1 = nn.GRUCell(insize, statesize)\n",
    "        self.gateLayer2 = nn.GRUCell(statesize, statesize)\n",
    "        self.gateLayer3 = nn.GRUCell(statesize, statesize)\n",
    "        self.out = nn.Linear(statesize, embedsize)\n",
    "    \n",
    "    def forward(self, inpt, state):\n",
    "        newstate1 = self.gateLayer1(inpt, state[:, 0])\n",
    "        newstate2 = self.gateLayer2(newstate1, state[:, 1])\n",
    "        newstate3 = self.gateLayer3(newstate2, state[:, 2])\n",
    "        embed = self.out(newstate3)\n",
    "        newstate = torch.cat((newstate1.view(-1, 1, self.statesize), \n",
    "                              newstate2.view(-1, 1, self.statesize), \n",
    "                              newstate3.view(-1, 1, self.statesize)), 1)\n",
    "        return embed, newstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, segments, statesize, embedsize):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.statesize = statesize\n",
    "        self.segments = segments\n",
    "        \n",
    "        insize = segments\n",
    "        outisze = segments\n",
    "        \n",
    "        self.gateLayer1 = nn.GRUCell(insize + embedsize, statesize)\n",
    "        self.gateLayer2 = nn.GRUCell(statesize, statesize)\n",
    "        self.gateLayer3 = nn.GRUCell(statesize, statesize)\n",
    "        self.linOut = nn.Linear(statesize, outisze)   \n",
    "    \n",
    "    def forward(self, inpt, state, embed):\n",
    "        newstate1 = self.gateLayer1(torch.cat((inpt, embed), 1), state[:, 0])\n",
    "        newstate2 = self.gateLayer2(newstate1, state[:, 1])\n",
    "        newstate3 = self.gateLayer3(newstate2, state[:, 2])\n",
    "        output = self.linOut(newstate3)\n",
    "        newstate = torch.cat((newstate1.view(-1, 1, self.statesize), \n",
    "                              newstate2.view(-1, 1, self.statesize), \n",
    "                              newstate3.view(-1, 1, self.statesize)), 1)\n",
    "        \n",
    "        return output, newstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = 512 #size of the hidden state\n",
    "EMBED = 25  #size of the encoding / embedding\n",
    "SEG = 25    #segment size / number of samples input at a time\n",
    "\n",
    "enc = Encoder(SEG, STATE, EMBED).cuda()\n",
    "dec = Decoder(SEG, STATE, EMBED).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encopt = optim.Adam(enc.parameters(), lr=0.0003)\n",
    "decopt = optim.Adam(dec.parameters(), lr=0.0003, weight_decay=0)\n",
    "\n",
    "X = X.cuda()\n",
    "\n",
    "NEPOCH = 3000\n",
    "for epoch in range(0, NEPOCH):\n",
    "    \n",
    "    encstate = torch.zeros(BATCH, 3, STATE).cuda()\n",
    "    decstate = torch.zeros(BATCH, 3, STATE).cuda()\n",
    "\n",
    "    #used to keep track of losses so we can take the mean later\n",
    "    epochlosses = []\n",
    "    \n",
    "    #First, traing the encoder\n",
    "    for step in range(0, X.shape[1], SEG):\n",
    "        inpt = X[:, step:step+SEG].cuda()\n",
    "        embed, encstate = enc(inpt, encstate)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    for step in range(0, X.shape[1], SEG):\n",
    "        #On the first step, input zeros\n",
    "        if step == 0:\n",
    "            inpt = torch.zeros(BATCH, SEG).cuda()\n",
    "        #otherwise randomly use teacher forcing ...\n",
    "        elif np.random.uniform() < 1 - (epoch/NEPOCH)*0.1:\n",
    "            inpt = X[:, step-SEG:step].cuda()\n",
    "        #...or don't use teacher forcing\n",
    "        else:\n",
    "            inpt = decoding\n",
    "            \n",
    "        #forward pass through the decoder    \n",
    "        decoding, decstate = dec(inpt, decstate, embed)\n",
    "        loss += F.mse_loss(decoding, X[:, step:step+SEG])\n",
    "\n",
    "    epochlosses.append(float(loss.detach())/LEN)\n",
    "    loss.backward()\n",
    "    encopt.step()\n",
    "    encopt.zero_grad()\n",
    "    decopt.step()\n",
    "    decopt.zero_grad()\n",
    "\n",
    "    print(epoch,np.mean(epochlosses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=np.inf)\n",
    "#move the encoder and decoder from gpu to cpu\n",
    "dec_c = dec.cpu()\n",
    "enc_c = enc.cpu()\n",
    "with torch.no_grad():\n",
    "    #factor is the number of times to loop the generation\n",
    "    #for making longer audio samples\n",
    "    factor = 24\n",
    "    #samp is the index for the embedding when generating\n",
    "    samp = 45\n",
    "\n",
    "    #embedding\n",
    "    embed = torch.zeros(1, 3, STATE)\n",
    "    outputs = torch.zeros(X.shape[1]*factor)\n",
    "    #encoder state\n",
    "    encstate = torch.zeros(1, 3, STATE)\n",
    "\n",
    "    #First, run a pass through the encoder\n",
    "    for step in range(0, X.shape[1]-SEG, SEG):\n",
    "        embed, encstate = enc_c(X[samp, step:step+SEG].view(1, -1).cpu(), encstate)\n",
    "\n",
    "    output = torch.zeros(1, SEG)\n",
    "    decstate = torch.zeros(1, 3, STATE)\n",
    "\n",
    "    #From the generated embedding create the output\n",
    "    for step in range(0, X.shape[1]*factor, SEG):\n",
    "        inpt = output\n",
    "        output, decstate = dec_c(inpt, decstate, embed)\n",
    "        outputs[step:step+SEG] = output\n",
    "        \n",
    "    plt.plot(outputs[0:5000])\n",
    "    plt.show()\n",
    "    plt.plot(X[samp, 0:].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output generated audio\n",
    "import wave\n",
    "oput = outputs.detach().numpy()\n",
    "w = wave.open('Long_MSE2.wav', 'wb')\n",
    "w.setparams((1, 2, 16000, oput.shape[0], 'NONE', 'NONE'))\n",
    "w.writeframes((oput * 10000).astype('int16'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
